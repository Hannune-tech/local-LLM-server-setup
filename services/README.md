# AI Services Deployment

This directory contains instructions and configurations for deploying various AI-related services using Docker.

## Motivation

Efficiently deploying and managing AI services is crucial for a functional AI development environment. These services form the backbone of your AI infrastructure, allowing you to run models, store and retrieve vector data, and manage your AI workflows.

## Contents

1. `ollama.md`: Deploy Ollama for running large language models (NVIDIA/AMD versions).
2. `vectorDB.sh`: Set up Elasticsearch and ChromaDB for efficient data indexing and search.
3. `ollama.py`: Python scripts demonstrating how to interact ollama.

## Usage

Run each deployment script as needed. Refer to the Python usage examples to understand how to interact with these services in your applications.
For detailed configuration options and advanced usage, refer to the comments in each script.
